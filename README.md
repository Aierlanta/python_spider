# python_spider
**学习爬虫的记录**
这个仓库用于记录学习爬虫过程中的一些过程
（然后，感谢这个过程中大佬们和好朋友们的的指点qwq）


# 关于这个仓库

novel_spider  预定的将要爬取http://trxs.cc 小说站，打算近期开工

tieba_spider_optimize.py  可以通过输入吧名和页码来爬取对应贴吧的页面，并保存为html文件至改代码的目录下，没什么实际用处

douban_spider.py  用于练习数据提取，能够爬取高分电影的前50条数据，可以通过修改url的方式来获取更多数据，将“page_limit=50”的参数修改即可实现

Kr36_spider.py  爬取36kr新闻站的爬虫，复习正则使用

haoduanzi_spider.py  爬取好段子网站（但这个站目前看来似乎已经废了），用于练习xpath

tieba_elaina__img_spider.py  用来爬伊雷娜吧的所有图片的爬虫，当然，如果改一下贴吧的url应该也是可以爬其他的吧的
